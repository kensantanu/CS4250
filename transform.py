import tokenizer
import stopping
import stemming

def tokenize():
    pass
    # query all professor in faculty collection db
    # for each professor
        # transform area of search (about me, research, etc) into tokens
        # remove common words
        # stem tokens
    # after finih we should get a list of tokens for each professor saved in db